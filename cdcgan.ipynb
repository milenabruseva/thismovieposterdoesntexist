{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mvutils\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n",
      "File \u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:49\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcycler\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cycler\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolorbar\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api\n",
      "File \u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py:21\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, collections, cm, colors, contour, ticker\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01martist\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmartist\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpatches\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpatches\u001B[39;00m\n",
      "File \u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\contour.py:13\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, docstring\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend_bases\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MouseButton\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpath\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpath\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mticker\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mticker\u001B[39;00m\n",
      "File \u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py:46\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[1;32m---> 46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     47\u001B[0m     _api, backend_tools \u001B[38;5;28;01mas\u001B[39;00m tools, cbook, colors, docstring, textpath,\n\u001B[0;32m     48\u001B[0m     tight_bbox, transforms, widgets, get_backend, is_interactive, rcParams)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pylab_helpers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Gcf\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend_managers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ToolManager\n",
      "File \u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_tools.py:24\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pylab_helpers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Gcf\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, cbook\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCursors\u001B[39;00m(enum\u001B[38;5;241m.\u001B[39mIntEnum):  \u001B[38;5;66;03m# Must subclass int for the macOS backend.\u001B[39;00m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:982\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:925\u001B[0m, in \u001B[0;36m_find_spec\u001B[1;34m(name, path, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1414\u001B[0m, in \u001B[0;36mfind_spec\u001B[1;34m(cls, fullname, path, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1386\u001B[0m, in \u001B[0;36m_get_spec\u001B[1;34m(cls, fullname, path, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1513\u001B[0m, in \u001B[0;36mfind_spec\u001B[1;34m(self, fullname, target)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:142\u001B[0m, in \u001B[0;36m_path_stat\u001B[1;34m(path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import dataloaders\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "DATA_PATH = \"data/tmdb-64\"\n",
    "TABLE_PATH = \"data/tmdb-movies-220921-clean.pkl\"\n",
    "workers = torch.get_num_threads()\n",
    "batch_size = 128\n",
    "image_size = 64\n",
    "number_of_channels = 3\n",
    "noise_vector_size = 100\n",
    "label_vector_size = 1\n",
    "generator_feature_maps = 128\n",
    "discriminator_feature_maps = 64\n",
    "num_epochs = 15\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "ngpu = 1\n",
    "number_of_samples = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_directory = os.path.join(os.getcwd(), 'cdcgan-output', datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "os.makedirs(output_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = dataloaders.PosterDataset(table_path=TABLE_PATH, img_root_path=DATA_PATH,\n",
    "                                    img_transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "                                    img_in_ram=False,\n",
    "                                    genre=None, genre_logic='and', og_lang=None, year=None, runtime=(40,np.inf),\n",
    "                                    max_num=None, sort='popularity')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers, pin_memory=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "if label_vector_size > 1:\n",
    "    sample_labels = torch.stack(real_batch[23], dim=1).type(torch.FloatTensor).to(device)[:number_of_samples]\n",
    "    sample_labels_generator = sample_labels[:, :, None, None].expand(number_of_samples, label_vector_size, 3, 1)\n",
    "else:\n",
    "    sample_labels = real_batch[8].type(torch.FloatTensor).to(device)[:number_of_samples]\n",
    "    sample_labels_generator = sample_labels[:, None, None, None].expand(number_of_samples, label_vector_size, 3, 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:number_of_samples], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "print('The dataset has ' + str(len(dataset)) + ' entries.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.deconv1_image = nn.ConvTranspose2d(noise_vector_size, generator_feature_maps * 4, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
    "        self.deconv1_image_bn = nn.BatchNorm2d(generator_feature_maps * 4)\n",
    "        self.deconv1_label = nn.ConvTranspose2d(label_vector_size, generator_feature_maps * 4, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
    "        self.deconv1_label_bn = nn.BatchNorm2d(generator_feature_maps * 4)\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose2d(generator_feature_maps * 8, generator_feature_maps * 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(generator_feature_maps * 4)\n",
    "\n",
    "        self.deconv3 =  nn.ConvTranspose2d(generator_feature_maps * 4, generator_feature_maps * 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(generator_feature_maps * 2)\n",
    "\n",
    "        self.deconv4 =  nn.ConvTranspose2d(generator_feature_maps * 2, generator_feature_maps, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(generator_feature_maps)\n",
    "\n",
    "        self.deconv5 =  nn.ConvTranspose2d(generator_feature_maps, number_of_channels, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        x = F.relu(self.deconv1_image_bn(self.deconv1_image(input)))\n",
    "        y = F.relu(self.deconv1_label_bn(self.deconv1_label(label)))\n",
    "        x = torch.cat([x, y], 1)\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        return torch.tanh(self.deconv5(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator_network = Generator().to(device)\n",
    "generator_network.apply(init_weights)\n",
    "print(generator_network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary(generator_network, input_size=[(noise_vector_size,1,3),(label_vector_size,1,3)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(3, discriminator_feature_maps, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.conv1_2 = nn.Conv2d(label_vector_size, discriminator_feature_maps, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(discriminator_feature_maps * 2, discriminator_feature_maps * 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.conv2_bn = nn.BatchNorm2d(discriminator_feature_maps * 4)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(discriminator_feature_maps * 4, discriminator_feature_maps * 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.conv3_bn = nn.BatchNorm2d(discriminator_feature_maps * 8)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(discriminator_feature_maps * 8, discriminator_feature_maps * 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.conv4_bn = nn.BatchNorm2d(discriminator_feature_maps * 16)\n",
    "        self.conv5 = nn.Conv2d(discriminator_feature_maps * 16, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
    "        self.conv6 = nn.Conv2d(1, 1, kernel_size=(3, 1), stride=(1, 1), bias=False)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        x = F.leaky_relu(self.conv1_1(input), 0.2)\n",
    "        y = F.leaky_relu(self.conv1_2(label), 0.2)\n",
    "        x = torch.cat([x, y], 1)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = torch.sigmoid(self.conv6(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discriminator_network = Discriminator(ngpu).to(device)\n",
    "discriminator_network.apply(init_weights)\n",
    "print(discriminator_network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary(discriminator_network, input_size=[(3,96,64),(label_vector_size,96,64)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_and_save_images(generator_network, epoch, noise, img_list, sample_labels):\n",
    "  with torch.no_grad():\n",
    "    images = generator_network(noise, sample_labels).detach().cpu()\n",
    "  fig = plt.figure(figsize=(8, 8))\n",
    "  plt.axis(\"off\")\n",
    "  img_list.append(vutils.make_grid(images, padding=2, normalize=True))\n",
    "  plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "  plt.show()\n",
    "  fig.savefig(output_directory + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "\n",
    "def save_checkpoint(generator_network, optimizer_generator, discriminator_network, optimizer_discriminator, epoch):\n",
    "  torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator_model_state_dict': generator_network.state_dict(),\n",
    "            'generator_optimizer_state_dict': optimizer_generator.state_dict(),\n",
    "            'discriminator_model_state_dict': discriminator_network.state_dict(),\n",
    "            'discriminator_optimizer_state_dict': optimizer_discriminator.state_dict(),\n",
    "            }, output_directory + '/gan_at_epoch_{:04d}.pt'.format(epoch))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "samples_noise = torch.randn(number_of_samples, noise_vector_size, 3, 1, device=device)\n",
    "\n",
    "optimizer_discriminator = optim.Adam(discriminator_network.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "optimizer_generator = optim.Adam(generator_network.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_list = []\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "current_iteration = 0\n",
    "discriminator_steps = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(pbar := tqdm(dataloader)):\n",
    "\n",
    "        # Train Discriminator\n",
    "        for step in range(discriminator_steps):\n",
    "            discriminator_network.zero_grad()\n",
    "            real = data[0].to(device)\n",
    "            if label_vector_size > 1:\n",
    "                input_labels = torch.stack(data[23], dim=1).type(torch.FloatTensor).to(device)\n",
    "                input_labels_generator = input_labels[:, :, None, None].expand(real.size(0), label_vector_size, 3, 1)\n",
    "                input_labels_discriminator = input_labels[:, :, None, None].expand(real.size(0), label_vector_size, 96, 64)\n",
    "            else:\n",
    "                input_labels = data[23].type(torch.FloatTensor).to(device)\n",
    "                input_labels_generator = input_labels[:, None, None, None].expand(real.size(0), label_vector_size, 3, 1)\n",
    "                input_labels_discriminator = input_labels[:, None, None, None].expand(real.size(0), label_vector_size, 96, 64)\n",
    "\n",
    "\n",
    "            label = torch.full((real.size(0),), real_label, dtype=torch.float, device=device)\n",
    "            output = discriminator_network(real, input_labels_discriminator).view(-1)\n",
    "            discriminator_error_on_real = loss_function(output, label)\n",
    "            discriminator_error_on_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            noise = torch.randn(real.size(0), noise_vector_size, 3, 1, device=device)\n",
    "            fake = generator_network(noise, input_labels_generator)\n",
    "            label.fill_(fake_label)\n",
    "            output = discriminator_network(fake.detach(), input_labels_discriminator).view(-1)\n",
    "            discriminator_error_on_fake = loss_function(output, label)\n",
    "            discriminator_error_on_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            discriminator_error = discriminator_error_on_real + discriminator_error_on_fake\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "        # Train Generator\n",
    "        for step in range(1):\n",
    "            generator_network.zero_grad()\n",
    "            label.fill_(real_label)\n",
    "            output = discriminator_network(fake, input_labels_discriminator).view(-1)\n",
    "            generator_error = loss_function(output, label)\n",
    "            generator_error.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizer_generator.step()\n",
    "\n",
    "        pbar.set_description('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs-1, discriminator_error.item(), generator_error.item(), D_x, D_G_z1, D_G_z2))\n",
    "        generator_losses.append(generator_error.item())\n",
    "        discriminator_losses.append(discriminator_error.item())\n",
    "\n",
    "        current_iteration += 1\n",
    "\n",
    "    generate_and_save_images(generator_network, epoch, samples_noise, img_list, sample_labels_generator)\n",
    "    save_checkpoint(generator_network, optimizer_generator, discriminator_network, optimizer_discriminator, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(generator_losses,label=\"Generator\")\n",
    "plt.plot(discriminator_losses,label=\"Discriminator\")\n",
    "plt.xlabel(\"Total Batch Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(f\"{output_directory}/training_loss.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_images = [Image.open(image) for image in glob.glob(f\"{output_directory}/image*.png\")]\n",
    "thumbnail = sample_images[0]\n",
    "thumbnail.save(f\"{output_directory}/dcgan.gif\", format=\"GIF\", append_images=sample_images, save_all=True, duration=1000, loop=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real = next(iter(dataloader))\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:number_of_samples], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"{output_directory}/real_vs_fake.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}