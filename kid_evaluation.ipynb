{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import random\n",
    "from os import path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import dataloaders\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from networks import dcgan\n",
    "from networks import wdcgan_gp\n",
    "from networks import sndcgan\n",
    "from networks import rdcgan\n",
    "from networks import cdcgan\n",
    "from networks import wcdcgan_gp\n",
    "from networks import sncdcgan\n",
    "from networks import rcdcgan\n",
    "\n",
    "from networks.utils import compute_kid_score\n",
    "from networks.utils import plot_grid\n",
    "from sample_and_visualize import sample_and_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Threads:  8\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = True\n",
    "if USE_CUDA and torch.cuda.is_available():\n",
    "    device = 'cuda'  #alt: \"cuda:0\"\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "PIN_MEMORY = True\n",
    "USE_MULTI_PROCESS_DATA_LOADING = True\n",
    "if USE_MULTI_PROCESS_DATA_LOADING:\n",
    "    NUM_THREADS = torch.get_num_threads()\n",
    "    print(\"Number of Threads: \", NUM_THREADS)\n",
    "else:\n",
    "    NUM_THREADS = 0\n",
    "    print(\"Not using Multi-Process Data Loading.\")\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED);\n",
    "\n",
    "### Data\n",
    "DATA_PATH = path.join(\"data\", \"tmdb-64\")\n",
    "TABLE_PATH = path.join(\"data\", \"tmdb-movies-220915-clean.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "### Architecture\n",
    "IMAGE_SIZE = 64\n",
    "IMAGE_SIZE_RATIO = 3\n",
    "NUM_IMG_CHANNELS = 3\n",
    "NUM_NOISE_VEC_CHANNELS = 100\n",
    "NUM_FEATURE_VEC_CHANNELS = 37\n",
    "BASE_NUM_OUT_CHANNELS_G_non_conditional = 64\n",
    "BASE_NUM_OUT_CHANNELS_G_conditional = 128\n",
    "BASE_NUM_OUT_CHANNELS_D = 64\n",
    "D_NORM_LAYER_TYPE = \"instance\"\n",
    "PADDING_MODE = \"reflect\"\n",
    "COLORMODE=\"RGB\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Poster subset:\n",
    "GENRE = None\n",
    "GENRE_LOGIC = 'and'\n",
    "OG_LANG = None\n",
    "YEAR = None\n",
    "RUNTIME = (40, np.inf)\n",
    "MAX_NUM = None\n",
    "SORT = None\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "mode = \"generated\"\n",
    "iterations = 5\n",
    "seed = 79469812346923649\n",
    "\n",
    "genres = [\"is_thriller\", \"is_western\", \"is_music\"]\n",
    "languages = [\"lang_en\", \"lang_ar\", \"lang_ja\", \"lang_zh\", \"lang_ru\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "poster_dataset = dataloaders.PosterDataset(table_path=TABLE_PATH, img_root_path=DATA_PATH,\n",
    "                                           img_transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "                                           colormode=COLORMODE,\n",
    "                                           img_in_ram=False,\n",
    "                                           genre=GENRE, genre_logic=GENRE_LOGIC, og_lang=OG_LANG, year=YEAR,\n",
    "                                           runtime=RUNTIME,\n",
    "                                           max_num=MAX_NUM, sort=SORT)\n",
    "\n",
    "posterloader = torch.utils.data.DataLoader(poster_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_THREADS,\n",
    "                                           pin_memory=PIN_MEMORY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "def evaluate_kid(model_name, model_dir, generator, conditional=False):\n",
    "    print(model_name)\n",
    "    models = [model for model in glob.glob(f\"{model_dir}/*.pt\")]\n",
    "    num_features = None\n",
    "    if conditional:\n",
    "        num_features = NUM_FEATURE_VEC_CHANNELS\n",
    "    print(\"KID score:\\n\")\n",
    "    means = []\n",
    "    stds = []\n",
    "    for model in models:\n",
    "        print(model)\n",
    "        generator.load_state_dict(torch.load(model)['generator_model_state_dict'])\n",
    "        generator.eval()\n",
    "        mean = compute_kid_score(generator, posterloader, mode, iterations, BATCH_SIZE, NUM_NOISE_VEC_CHANNELS,\n",
    "                          IMAGE_SIZE_RATIO, device, num_features)\n",
    "        means.append(mean)\n",
    "        #stds.append(std)\n",
    "    kid_scores = {\"means\": means, \"stds\": stds}\n",
    "    with open(path.join(model_dir, f\"{model_name}_kid.pkl\"), 'wb') as f:\n",
    "        pickle.dump(kid_scores, f)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(len(means)), means)\n",
    "    plt.show()\n",
    "    fig.savefig(path.join(model_dir, f\"{model_name}_kid.png\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCGAN\n",
      "KID score:\n",
      "\n",
      "output-runs\\dcgan-output\\2022-09-26_21-16-09\\gan_at_epoch_0000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `FrechetInceptionDistance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\_matfuncs_sqrtm.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  arg2 = norm(X.dot(X) - A, 'fro')**2 / norm(A, 'fro')\n",
      " 20%|██        | 1/5 [00:14<00:59, 14.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.205965042114258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:27<00:41, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.789871215820312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:40<00:26, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.117815017700195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:53<00:12, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.258699417114258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:05<00:00, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.34008026123047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m generator, _ \u001B[38;5;241m=\u001B[39m dcgan\u001B[38;5;241m.\u001B[39mcreate_gan(img_size\u001B[38;5;241m=\u001B[39mIMAGE_SIZE, img_ratio\u001B[38;5;241m=\u001B[39mIMAGE_SIZE_RATIO,\n\u001B[0;32m      2\u001B[0m                                             num_img_channels\u001B[38;5;241m=\u001B[39mNUM_IMG_CHANNELS,\n\u001B[0;32m      3\u001B[0m                                             num_noise_vec_channels\u001B[38;5;241m=\u001B[39mNUM_NOISE_VEC_CHANNELS,\n\u001B[0;32m      4\u001B[0m                                             base_num_out_channels_g\u001B[38;5;241m=\u001B[39mBASE_NUM_OUT_CHANNELS_G_non_conditional,\n\u001B[0;32m      5\u001B[0m                                             base_num_out_channels_d\u001B[38;5;241m=\u001B[39mBASE_NUM_OUT_CHANNELS_D, padding_mode\u001B[38;5;241m=\u001B[39mPADDING_MODE,\n\u001B[0;32m      6\u001B[0m                                             device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mevaluate_kid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDCGAN\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput-runs\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mdcgan-output\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43m2022-09-26_21-16-09\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconditional\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36mevaluate_kid\u001B[1;34m(model_name, model_dir, generator, conditional)\u001B[0m\n\u001B[0;32m     14\u001B[0m generator\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(model)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenerator_model_state_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     15\u001B[0m generator\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m---> 16\u001B[0m mean \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_kid_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mposterloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mNUM_NOISE_VEC_CHANNELS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mIMAGE_SIZE_RATIO\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m means\u001B[38;5;241m.\u001B[39mappend(mean)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#stds.append(std)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\HD\\thismovieposterdoesntexist\\networks\\utils.py:298\u001B[0m, in \u001B[0;36mcompute_kid_score\u001B[1;34m(generator, posterloader, mode, iterations, subset_size, num_noise_vec_channels, img_size_ratio, device, num_feature_vec_channels)\u001B[0m\n\u001B[0;32m    296\u001B[0m mean \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([stat\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m stat \u001B[38;5;129;01min\u001B[39;00m stats]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mfloat\u001B[39m(iterations)\n\u001B[0;32m    297\u001B[0m \u001B[38;5;66;03m#mean_std = sum([stat[1] for stat in stats]) / float(iterations)\u001B[39;00m\n\u001B[1;32m--> 298\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMode: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m mode \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m | Mean: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[43mmean\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m()))\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mean\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'float' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "generator, _ = dcgan.create_gan(img_size=IMAGE_SIZE, img_ratio=IMAGE_SIZE_RATIO,\n",
    "                                            num_img_channels=NUM_IMG_CHANNELS,\n",
    "                                            num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                            base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_non_conditional,\n",
    "                                            base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D, padding_mode=PADDING_MODE,\n",
    "                                            device=device)\n",
    "evaluate_kid(\"DCGAN\", \"output-runs\\\\dcgan-output\\\\2022-09-26_21-16-09\", generator, conditional=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, _ = wdcgan_gp.create_gan(num_img_channels=NUM_IMG_CHANNELS,\n",
    "                                             num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                             base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_non_conditional,\n",
    "                                             base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D,\n",
    "                                             d_norm_layer_type=D_NORM_LAYER_TYPE, padding_mode=PADDING_MODE,\n",
    "                                             device=device)\n",
    "evaluate_kid(\"WDCGAN\", \"output-runs\\\\wdcgan-output\\\\2022-09-25_04-48-49\", generator, conditional=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, _ = sndcgan.create_gan(num_img_channels=NUM_IMG_CHANNELS,\n",
    "                                              num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                              base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_non_conditional,\n",
    "                                              base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D, padding_mode=PADDING_MODE,\n",
    "                                              device=device)\n",
    "evaluate_kid(\"SNDCGAN\", \"output-runs\\\\sndcgan-output\\\\2022-09-27_04-18-01\", generator, conditional=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, discriminator = rdcgan.create_gan(img_size=IMAGE_SIZE, img_ratio=IMAGE_SIZE_RATIO,\n",
    "                                            num_img_channels=NUM_IMG_CHANNELS,\n",
    "                                            num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                            base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_non_conditional,\n",
    "                                            base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D, padding_mode=PADDING_MODE,\n",
    "                                            device=device)\n",
    "#evaluate_kid(\"RaDCGAN\", \"output-runs\\\\radcgan-output\\\\2022-09-25_04-48-49\", generator, conditional=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, _ = cdcgan.create_gan(num_img_channels=NUM_IMG_CHANNELS,\n",
    "                                             num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                             base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_conditional,\n",
    "                                             base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D, padding_mode=PADDING_MODE,\n",
    "                                             num_feature_vec_channels=NUM_FEATURE_VEC_CHANNELS, device=device)\n",
    "evaluate_kid(\"cDCGAN\", \"output-runs\\\\cdcgan-output\\\\2022-09-27_00-55-04\", generator, conditional=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, _ = wcdcgan_gp.create_gan(num_img_channels=NUM_IMG_CHANNELS, num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                    base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_conditional,\n",
    "                                    base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D, padding_mode=PADDING_MODE,\n",
    "                                    num_feature_vec_channels=NUM_FEATURE_VEC_CHANNELS,\n",
    "                                    d_norm_layer_type=D_NORM_LAYER_TYPE, device=device)\n",
    "evaluate_kid(\"WcDCGAN\", \"output-runs\\\\wcdcgan-output\\\\2022-09-25_23-40-46\", generator, conditional=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, _ = sncdcgan.create_gan(num_img_channels=NUM_IMG_CHANNELS,\n",
    "                                               num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                               base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_conditional,\n",
    "                                               base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D,\n",
    "                                               padding_mode=PADDING_MODE,\n",
    "                                               num_feature_vec_channels=NUM_FEATURE_VEC_CHANNELS, device=device)\n",
    "evaluate_kid(\"SNcDCGAN\", \"output-runs\\\\sncdcgan-output\\\\2022-09-27_06-53-59\", generator, conditional=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, _ = rcdcgan.create_gan(img_size=IMAGE_SIZE, img_ratio=IMAGE_SIZE_RATIO,\n",
    "                                              num_img_channels=NUM_IMG_CHANNELS,\n",
    "                                              num_noise_vec_channels=NUM_NOISE_VEC_CHANNELS,\n",
    "                                            num_feature_vec_channels=NUM_FEATURE_VEC_CHANNELS,\n",
    "                                              base_num_out_channels_g=BASE_NUM_OUT_CHANNELS_G_conditional,\n",
    "                                              base_num_out_channels_d=BASE_NUM_OUT_CHANNELS_D,\n",
    "                                              padding_mode=PADDING_MODE,\n",
    "                                              device=device)\n",
    "#evaluate_kid(\"RacDCGAN\", \"output-runs\\\\racdcgan-output\\\\2022-09-25_04-48-49\", generator, conditional=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}